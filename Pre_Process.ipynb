{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Fetching data from the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "url = \"https://www.gutenberg.org/cache/epub/59824/pg59824-images.html\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Titles are displayed in <h4> and <h5>\n",
    "# tags , while the poem themselves are\n",
    "# displayed in <p> tags.    \n",
    "\n",
    "\n",
    "# The first few tags are not useful\n",
    "\n",
    "titles = soup.find_all(['h4', 'h5'])[7:]                                    \n",
    "poems = soup.find_all('p')[8:]\n",
    "\n",
    "poems_data = []\n",
    "for title, poem in zip(titles, poems):\n",
    "    poems_data.append({\n",
    "        \"title\": title.text.strip(),\n",
    "        \"content\": poem.text.strip()\n",
    "    })\n",
    "\n",
    "with open('Robert_Frost_Poem_Collection.json', 'w') as f:\n",
    "    json.dump(poems_data, f, indent=4)\n",
    "\n",
    "# !!! The data is still not proper.\n",
    "# Additional Manual cleaning of data needs to be done.\n",
    "\n",
    "# The file name is intentionally written as Robert_Frost_Poem_Collection and not Robert_Frost_Poem_Collections \n",
    "# so as not to accidentally write over the previous file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the sample implementation of BPE in tiktoken (https://github.com/openai/tiktoken/blob/main/tiktoken/_educational.py)\n",
    "# It is modified to work with our code.\n",
    "\n",
    "\n",
    "\"\"\"This is an educational implementation of the byte pair encoding algorithm.\"\"\"\n",
    "import collections\n",
    "import regex\n",
    "\n",
    "gpt2_regex = (r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?[\\p{L}]+| ?[\\p{N}]+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\" )\n",
    "gpt4_regex = (r\"\"\"'(?i:[sdmt]|ll|ve|re)|[^\\r\\n\\p{L}\\p{N}]?+\\p{L}+|\\p{N}{1,3}| ?[^\\s\\p{L}\\p{N}]++[\\r\\n]*|\\s*[\\r\\n]|\\s+(?!\\S)|\\s+\"\"\")\n",
    "\n",
    "class SimpleBytePairEncoding:\n",
    "    def __init__(self, *, mergeable_ranks: dict[bytes, int]) -> None:\n",
    "        \"\"\"Creates an Encoding object.\"\"\"\n",
    "        # A regex pattern string that is used to split the input text\n",
    "        self.pat_str = gpt4_regex\n",
    "        # A dictionary mapping token bytes to their ranks. The ranks correspond to merge priority\n",
    "        self.mergeable_ranks = mergeable_ranks\n",
    "\n",
    "        self._decoder = {token: token_bytes for token_bytes, token in mergeable_ranks.items()}\n",
    "        self._pat = regex.compile(gpt4_regex)\n",
    "\n",
    "    def encode(self, text: str) -> list[int]:\n",
    "        \"\"\"Encodes a string into tokens.\n",
    "\n",
    "        >>> enc.encode(\"hello world\")\n",
    "        [388, 372]\n",
    "        \"\"\"\n",
    "        # Use the regex to split the text into (approximately) words\n",
    "        words = self._pat.findall(text)\n",
    "        tokens = []\n",
    "        for word in words:\n",
    "            # Turn each word into tokens, using the byte pair encoding algorithm\n",
    "            word_bytes = word.encode(\"utf-8\")\n",
    "            word_tokens = bpe_encode(self.mergeable_ranks, word_bytes)\n",
    "            tokens.extend(word_tokens)\n",
    "        return tokens\n",
    "    \n",
    "    def decode_bytes(self, tokens: list[int]) -> bytes:\n",
    "        \"\"\"Decodes a list of tokens into bytes.\n",
    "\n",
    "        >>> enc.decode_bytes([388, 372])\n",
    "        b'hello world'\n",
    "        \"\"\"\n",
    "        return b\"\".join(self._decoder[token] for token in tokens)\n",
    "\n",
    "    def decode(self, tokens: list[int]) -> str:\n",
    "        \"\"\"Decodes a list of tokens into a string.\n",
    "\n",
    "        Decoded bytes are not guaranteed to be valid UTF-8. In that case, we replace\n",
    "        the invalid bytes with the replacement character \"ï¿½\".\n",
    "\n",
    "        >>> enc.decode([388, 372])\n",
    "        'hello world'\n",
    "        \"\"\"\n",
    "        return self.decode_bytes(tokens).decode(\"utf-8\", errors=\"replace\")\n",
    "\n",
    "    @staticmethod\n",
    "    def train(training_data: str, vocab_size: int):\n",
    "        \"\"\"Train a BPE tokeniser on some data!\"\"\"\n",
    "        mergeable_ranks = bpe_train(data=training_data, vocab_size=vocab_size)\n",
    "        return SimpleBytePairEncoding(mergeable_ranks=mergeable_ranks)\n",
    "\n",
    "\n",
    "def bpe_encode(mergeable_ranks: dict[bytes, int], input: bytes) -> list[int]:\n",
    "    parts = [bytes([b]) for b in input]\n",
    "    while True:\n",
    "\n",
    "        # Iterate over all pairs and find the pair we want to merge the most\n",
    "        min_idx = None\n",
    "        min_rank = None\n",
    "        for i, pair in enumerate(zip(parts[:-1], parts[1:])):\n",
    "            rank = mergeable_ranks.get(pair[0] + pair[1])\n",
    "            if rank is not None and (min_rank is None or rank < min_rank):\n",
    "                min_idx = i\n",
    "                min_rank = rank\n",
    "\n",
    "        # If there were no pairs we could merge, we're done!\n",
    "        if min_rank is None:\n",
    "            break\n",
    "        assert min_idx is not None\n",
    "\n",
    "        # Otherwise, merge that pair and leave the rest unchanged. Then repeat.\n",
    "        parts = parts[:min_idx] + [parts[min_idx] + parts[min_idx + 1]] + parts[min_idx + 2 :]\n",
    "\n",
    "    tokens = [mergeable_ranks[part] for part in parts]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def bpe_train(data: str, vocab_size: int) -> dict[bytes, int]:\n",
    "    # First, add tokens for each individual byte value\n",
    "    if vocab_size < 2**8:\n",
    "        raise ValueError(\"vocab_size must be at least 256, so we can encode all bytes\")\n",
    "    ranks = {}\n",
    "    for i in range(2**8):\n",
    "        ranks[bytes([i])] = i\n",
    "\n",
    "    # Splinter up our data into lists of bytes\n",
    "    # data = \"Hello world\"\n",
    "    # words = [\n",
    "    #     [b'H', b'e', b'l', b'l', b'o'],\n",
    "    #     [b' ', b'w', b'o', b'r', b'l', b'd']\n",
    "    # ]\n",
    "    words: list[list[bytes]] = [\n",
    "        [bytes([b]) for b in word.encode(\"utf-8\")] for word in regex.findall(gpt4_regex, data)\n",
    "    ]\n",
    "\n",
    "    # Now, use our data to figure out which merges we should make\n",
    "    while len(ranks) < vocab_size:\n",
    "        # Find the most common pair. This will become our next token\n",
    "        stats = collections.Counter()\n",
    "        for piece in words:\n",
    "            for pair in zip(piece[:-1], piece[1:]):\n",
    "                stats[pair] += 1\n",
    "\n",
    "        most_common_pair = max(stats, key=lambda x: stats[x])\n",
    "        token_bytes = most_common_pair[0] + most_common_pair[1]\n",
    "        token = len(ranks)\n",
    "        # Add the new token!\n",
    "        ranks[token_bytes] = token\n",
    "\n",
    "        # Now merge that most common pair in all the words. That is, update our training data\n",
    "        # to reflect our decision to make that pair into a new token.\n",
    "        new_words = []\n",
    "        for word in words:\n",
    "            new_word = []\n",
    "            i = 0\n",
    "            while i < len(word) - 1:\n",
    "                if (word[i], word[i + 1]) == most_common_pair:\n",
    "                    # We found our pair! Merge it\n",
    "                    new_word.append(token_bytes)\n",
    "                    i += 2\n",
    "                else:\n",
    "                    new_word.append(word[i])\n",
    "                    i += 1\n",
    "            if i == len(word) - 1:\n",
    "                new_word.append(word[i])\n",
    "            new_words.append(new_word)\n",
    "        words = new_words\n",
    "\n",
    "    return ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dataset = json.load(open('Robert_Frost_Poem_Collections.json'))\n",
    "\n",
    "titles = []                             #titles of the poems\n",
    "contents = []                           #actual content of the poems\n",
    "for item in dataset:\n",
    "  titles.append(item.get('title'))\n",
    "  contents.append(item.get('content'))\n",
    "\n",
    "training_text = ''.join(contents)\n",
    "\n",
    "#Tokenizer object , which will encode and decode\n",
    "#our text to tokens.\n",
    "\n",
    "tokenizer = SimpleBytePairEncoding(mergeable_ranks=dict()).train(training_text,vocab_size=1000)                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded message  : [72, 285, 307, 111, 313, 736, 299, 259, 930, 537, 361, 32, 63, 32, 40, 73, 643, 396, 32, 59, 346, 286, 867, 867, 784, 281, 41] \n",
      "Original message : How poetic of a road this is ? (I must say ; for I am amused) \n",
      "Decoded message  : How poetic of a road this is ? (I must say ; for I am amused) \n",
      "\n",
      "\n",
      "Original size     : 61 \n",
      "Encoded size      : 27 \n",
      "Compression Ratio : 2.2593\n"
     ]
    }
   ],
   "source": [
    "message = \"How poetic of a road this is ? (I must say ; for I am amused)\"\n",
    "encoded_message = tokenizer.encode(message)\n",
    "decoded_message = tokenizer.decode(encoded_message)\n",
    "print(f\"Encoded message  : {encoded_message} \")\n",
    "print(f\"Original message : {message} \")\n",
    "print(f\"Decoded message  : {decoded_message} \")\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(f\"Original size     : {len(message)} \")\n",
    "print(f\"Encoded size      : {len(encoded_message)} \")\n",
    "print(f\"Compression Ratio : {len(decoded_message)/len(encoded_message):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Creating Input and Output Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def pad_sequences_pytorch(sequences, maxlen, padding_value=0):\n",
    "    tensor_list = [torch.tensor(seq, dtype=torch.long) for seq in sequences]\n",
    "    padded_seqs = pad_sequence(tensor_list, batch_first=True, padding_value=padding_value)\n",
    "    \n",
    "    if padded_seqs.size(1) < maxlen: padded_seqs = F.pad(padded_seqs, (maxlen - padded_seqs.size(1), 0), value=padding_value)\n",
    "    else: padded_seqs = padded_seqs[:, -maxlen:]\n",
    "        \n",
    "    return padded_seqs\n",
    "\n",
    "\n",
    "def createInputOutput(contents , step_size=10):\n",
    "    input_seq = []\n",
    "    output_seq = []\n",
    "\n",
    "    encoded_content = [tokenizer.encode(content) for content in contents]\n",
    "    max_encoded_content_length = max([len(i) for i in encoded_content])\n",
    "\n",
    "    for poems in encoded_content:\n",
    "        for position in range(0,len(poems)-1,step_size):\n",
    "            new_input = poems[:position]\n",
    "            new_output = poems[position]\n",
    "            \n",
    "            padded_input = pad_sequences_pytorch([new_input], maxlen=max_encoded_content_length, padding_value=0)\n",
    "\n",
    "            input_seq.append(padded_input[0])\n",
    "            output_seq.append(new_output)\n",
    "\n",
    "    return torch.stack(input_seq), F.one_hot(torch.tensor(output_seq , dtype=torch.long), num_classes=len(tokenizer.mergeable_ranks)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "# Initialize the HuggingFace tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Define a function to pad sequences using PyTorch\n",
    "def pad_sequences_pytorch(sequences, maxlen, padding_value=0):\n",
    "    tensor_list = [torch.tensor(seq, dtype=torch.long) for seq in sequences]\n",
    "    padded_seqs = pad_sequence(tensor_list, batch_first=True, padding_value=padding_value)\n",
    "    \n",
    "    if padded_seqs.size(1) < maxlen:\n",
    "        padded_seqs = F.pad(padded_seqs, (maxlen - padded_seqs.size(1), 0), value=padding_value)\n",
    "    else:\n",
    "        padded_seqs = padded_seqs[:, -maxlen:]\n",
    "        \n",
    "    return padded_seqs\n",
    "\n",
    "# Function to create input and output sequences\n",
    "def createInputOutput(contents, step_size=10):\n",
    "    input_seq = []\n",
    "    output_seq = []\n",
    "\n",
    "    # Encode content using the tokenizer\n",
    "    encoded_content = [tokenizer.encode(content) for content in contents]\n",
    "    max_encoded_content_length = max(len(i) for i in encoded_content)\n",
    "\n",
    "    for poems in encoded_content:\n",
    "        for position in range(0, len(poems)-1, step_size):\n",
    "            new_input = poems[:position]\n",
    "            new_output = poems[position]\n",
    "            \n",
    "            padded_input = pad_sequences_pytorch([new_input], maxlen=max_encoded_content_length, padding_value=0)\n",
    "\n",
    "            input_seq.append(padded_input[0])\n",
    "            output_seq.append(new_output)\n",
    "\n",
    "    return torch.stack(input_seq), F.one_hot(torch.tensor(output_seq, dtype=torch.long), num_classes=len(tokenizer)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([11850, 3642]), torch.Size([11850, 1000]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq, output_seq = createInputOutput(contents[:10],1)\n",
    "\n",
    "input_seq.shape , output_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  0,   0,   0,  ..., 467, 607, 369]), 369)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq[4] , sum([i for i in range(len(output_seq[3])) if output_seq[3][i] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 5.9710\n",
      "Epoch [2/10], Loss: 5.1779\n",
      "Epoch [3/10], Loss: 4.7078\n",
      "Epoch [4/10], Loss: 4.4120\n",
      "Epoch [5/10], Loss: 4.2001\n",
      "Epoch [6/10], Loss: 4.0417\n",
      "Epoch [7/10], Loss: 3.9007\n",
      "Epoch [8/10], Loss: 3.7947\n",
      "Epoch [9/10], Loss: 3.7001\n",
      "Epoch [10/10], Loss: 3.6166\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "class BiLSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n",
    "        super(BiLSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.bilstm1 = nn.LSTM(embed_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
    "        self.bilstm2 = nn.LSTM(hidden_dim * 2, hidden_dim, bidirectional=True, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.5)  \n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.bilstm1(x)\n",
    "        x, _ = self.bilstm2(x)\n",
    "        x = self.dropout(x)  \n",
    "        x = self.fc(x[:, -1, :])\n",
    "        return x\n",
    "    \n",
    "class ModifiedBiLSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n",
    "        super(ModifiedBiLSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.bilstm1 = nn.LSTM(embed_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
    "        self.bilstm2 = nn.LSTM(hidden_dim * 2, hidden_dim, bidirectional=True, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.9)\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)  \n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)      \n",
    "        self.relu = nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.bilstm1(x)\n",
    "        x, _ = self.bilstm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x[:, -1, :]   \n",
    "        x = self.fc1(x)   \n",
    "        x = self.relu(x)  \n",
    "        x = self.fc2(x)   \n",
    "        return x\n",
    "    \n",
    "class OnlineLSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n",
    "        super(OnlineLSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.bilstm = nn.LSTM(embed_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.bilstm(x)\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        return x\n",
    "\n",
    "\n",
    "vocab_size = len(tokenizer.mergeable_ranks)\n",
    "embed_dim = 10  \n",
    "hidden_dim = 15 \n",
    "output_dim = vocab_size  \n",
    "\n",
    "# model = BiLSTMModel(vocab_size, embed_dim, hidden_dim , output_dim).to(device)\n",
    "model = OnlineLSTMModel(vocab_size, embed_dim, hidden_dim , output_dim).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)  # type: ignore\n",
    "\n",
    "train_dataset = TensorDataset(input_seq.to(device), output_seq.to(device))\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  \n",
    "        optimizer.zero_grad()  \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()  \n",
    "        optimizer.step() \n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75965/500112481.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_data = torch.tensor(some_input_data, dtype=torch.long).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 highest values and their corresponding indices in the tensor:\n",
      "Value: 8.583165168762207, Index: 692 , Token: One\n",
      "Value: 7.986666679382324, Index: 77 , Token: M\n",
      "Value: 7.751272678375244, Index: 776 , Token: On\n",
      "Value: 7.600372314453125, Index: 341 , Token: He\n",
      "Value: 7.331014633178711, Index: 73 , Token: I\n",
      "Value: 7.114770412445068, Index: 951 , Token: All\n",
      "Value: 7.0151448249816895, Index: 527 , Token: She\n",
      "Value: 6.957378387451172, Index: 446 , Token: \"W\n",
      "Value: 6.941136837005615, Index: 833 , Token: Some\n",
      "Value: 6.928683280944824, Index: 428 , Token: It\n",
      "\n",
      "  One ,  I  can 't y es ,  I 'm s y es ,  I  have  to  c ur om \n",
      " O er .\n",
      " I 'm s ink s il as  you  can 't y es ,  I  can 't y es ,  I 'm s y es ,  and\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def generate(inp, temperature , loop):\n",
    "    some_input_data = tokenizer.encode(inp)\n",
    "    some_input_data = pad_sequences_pytorch([some_input_data], maxlen=input_seq.shape[1], padding_value=0)\n",
    "\n",
    "    input_data = torch.tensor(some_input_data, dtype=torch.long).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad(): outputs = model(input_data)\n",
    "\n",
    "    logits = outputs / temperature\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "    if (loop == 0):\n",
    "        top_values, top_indices = torch.topk(outputs, 10, dim=-1)\n",
    "\n",
    "        sorted_top_values, sorted_indices = top_values.sort(descending=True)\n",
    "        sorted_top_indices = top_indices.gather(dim=-1, index=sorted_indices)\n",
    "\n",
    "        print(\"Top 10 highest values and their corresponding indices in the tensor:\")\n",
    "        for i in range(10): print(f\"Value: {sorted_top_values[0][i].item()}, Index: {sorted_top_indices[0][i].item()} , Token: {tokenizer.decode([sorted_top_indices[0][i].item()])}\") #type: ignore\n",
    "\n",
    "\n",
    "    next_word_index = torch.multinomial(probs[0], num_samples=1).item()\n",
    "    response = tokenizer.decode([next_word_index])  # type: ignore\n",
    "\n",
    "    # print(inp + response)\n",
    "    return response\n",
    "\n",
    "inp = \"\"\n",
    "for i in range(50):\n",
    "    outs = generate(inp, 0.25 , i) \n",
    "    inp = inp + \" \" + outs\n",
    "\n",
    "print('\\n',inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sera t\n",
      " Se\n",
      "ra\n",
      " t\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode([1001,430,256]))\n",
    "print(tokenizer.decode([1001]))\n",
    "print(tokenizer.decode([430]))\n",
    "print(tokenizer.decode([256]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Plot the counts\u001b[39;00m\n\u001b[1;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m---> 15\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbar\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50035\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_counts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass Index\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of Occurrences\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/matplotlib/pyplot.py:2956\u001b[0m, in \u001b[0;36mbar\u001b[0;34m(x, height, width, bottom, align, data, **kwargs)\u001b[0m\n\u001b[1;32m   2945\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mbar)\n\u001b[1;32m   2946\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbar\u001b[39m(\n\u001b[1;32m   2947\u001b[0m     x: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2954\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2955\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BarContainer:\n\u001b[0;32m-> 2956\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbar\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbottom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbottom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2961\u001b[0m \u001b[43m        \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2962\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2963\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/matplotlib/__init__.py:1473\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1471\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1472\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1473\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1474\u001b[0m \u001b[43m            \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1475\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1476\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1478\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1479\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1480\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/matplotlib/axes/_axes.py:2597\u001b[0m, in \u001b[0;36mAxes.bar\u001b[0;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[1;32m   2595\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# horizontal\u001b[39;00m\n\u001b[1;32m   2596\u001b[0m         r\u001b[38;5;241m.\u001b[39msticky_edges\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mappend(l)\n\u001b[0;32m-> 2597\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_patch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2598\u001b[0m     patches\u001b[38;5;241m.\u001b[39mappend(r)\n\u001b[1;32m   2600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xerr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m yerr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/matplotlib/axes/_base.py:2414\u001b[0m, in \u001b[0;36m_AxesBase.add_patch\u001b[0;34m(self, p)\u001b[0m\n\u001b[1;32m   2412\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2413\u001b[0m     p\u001b[38;5;241m.\u001b[39mset_clip_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch)\n\u001b[0;32m-> 2414\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_patch_limits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2415\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_children\u001b[38;5;241m.\u001b[39mappend(p)\n\u001b[1;32m   2416\u001b[0m p\u001b[38;5;241m.\u001b[39m_remove_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_children\u001b[38;5;241m.\u001b[39mremove\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/matplotlib/axes/_base.py:2455\u001b[0m, in \u001b[0;36m_AxesBase._update_patch_limits\u001b[0;34m(self, patch)\u001b[0m\n\u001b[1;32m   2453\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m updatey \u001b[38;5;129;01mand\u001b[39;00m patch_trf \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xaxis_transform():\n\u001b[1;32m   2454\u001b[0m         updatey \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 2455\u001b[0m trf_to_data \u001b[38;5;241m=\u001b[39m \u001b[43mpatch_trf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransData\u001b[49m\n\u001b[1;32m   2456\u001b[0m xys \u001b[38;5;241m=\u001b[39m trf_to_data\u001b[38;5;241m.\u001b[39mtransform(vertices)\n\u001b[1;32m   2457\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_datalim(xys, updatex\u001b[38;5;241m=\u001b[39mupdatex, updatey\u001b[38;5;241m=\u001b[39mupdatey)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/matplotlib/transforms.py:1460\u001b[0m, in \u001b[0;36mTransform.__sub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, Transform):\n\u001b[1;32m   1459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m-> 1460\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mremainder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_tree\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_break_from_left_to_right\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msub_tree\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mremainder\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/matplotlib/transforms.py:2402\u001b[0m, in \u001b[0;36mCompositeGenericTransform._iter_break_from_left_to_right\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_iter_break_from_left_to_right\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 2402\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_a\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_break_from_left_to_right\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   2403\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_b\u001b[49m\n\u001b[1;32m   2404\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m left, right \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_b\u001b[38;5;241m.\u001b[39m_iter_break_from_left_to_right():\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/matplotlib/transforms.py:2401\u001b[0m, in \u001b[0;36mCompositeGenericTransform._iter_break_from_left_to_right\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2398\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 2401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_iter_break_from_left_to_right\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2402\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m left, right \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_a\u001b[38;5;241m.\u001b[39m_iter_break_from_left_to_right():\n\u001b[1;32m   2403\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m left, right \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_b\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Assuming output_seq is the tensor with one-hot encoded vectors\n",
    "output_seq_plot = output_seq.argmax(dim=1).cpu().numpy()  # Convert one-hot to class indices\n",
    "\n",
    "# Count occurrences of each class (1-1000)\n",
    "class_counts = torch.bincount(torch.tensor(output_seq_plot), minlength=50035)  # Ensure length 1001 to include index 1000\n",
    "\n",
    "# Exclude the count for index 0 if your classes start from 1\n",
    "class_counts = class_counts[1:]  # Remove count for index 0 if not used\n",
    "\n",
    "# Plot the counts\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(1, 50035), class_counts.numpy())\n",
    "plt.xlabel('Class Index')\n",
    "plt.ylabel('Number of Occurrences')\n",
    "plt.title('Occurrences of Each Class (1-1000) in Output Sequences')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
